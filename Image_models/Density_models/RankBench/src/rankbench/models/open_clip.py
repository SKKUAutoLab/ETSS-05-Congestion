import torch
from torch import nn    
import open_clip

PRETRAINED_TAGS = {'convnext_large_d_320': 'laion2b_s29b_b131k_ft_soup'}

class OpenCLIP(nn.Module):
    def __init__(self, variant, pretrained=True):
        super().__init__()
        if variant not in PRETRAINED_TAGS:
            raise ValueError(f"Variant {variant} not found in PRETRAINED_TAGS")
        pretrained_tag = PRETRAINED_TAGS[variant] if pretrained else None
        print(f"Available GPUs: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
        device_ids = list(range(torch.cuda.device_count()))
        if not device_ids:
            raise RuntimeError("No CUDA devices available")
        torch.cuda.set_device(0)
        base_model, _, self.preprocess = open_clip.create_model_and_transforms(variant, pretrained=pretrained_tag, jit=False)
        if len(device_ids) > 1:
            self.model = nn.DataParallel(base_model, device_ids=device_ids)
        else:
            self.model = base_model

    def __call__(self):
        return self.model, self.preprocess
    
    def tokenize(self, texts):
        return open_clip.tokenize(texts).cuda()

    def encode_image(self, image):
        if isinstance(self.model, nn.DataParallel):
            return self.model.module.encode_image(image)
        return self.model.encode_image(image)
    
    def encode_text(self, text):
        if isinstance(self.model, nn.DataParallel):
            return self.model.module.encode_text(text)
        return self.model.encode_text(text)

    def unfreeze_image_encoder(self):
        if isinstance(self.model, nn.DataParallel):
            self.model.module.visual.requires_grad_(True)
        else:
            self.model.visual.requires_grad_(True)
        
    def freeze_image_encoder(self):
        if isinstance(self.model, nn.DataParallel):
            self.model.module.visual.requires_grad_(False)
        else:
            self.model.visual.requires_grad_(False)